{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Scraping de Dados</h1>\n",
    "\n",
    "Para investigarmos as causas de possíveis diferenças de qualidade de atendimento, precisamos de informações descritivas dos bairros onde esses ocorrem. Do site http://www2.recife.pe.gov.br/servico/perfil-dos-bairros, onde descreve-se cada bairro de Recife, extrairemos informações importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as rq\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A URL para cada bairro é convenientemente formada por duas partes fixas unidas pelo nome do bairro, que deve ser escrito com somente letras minúsculas e espaços substituídos por traços.\n",
    "\n",
    "Alguns bairros têm seus nomes comentados - são os que provocavam falhas com as funções de scraping, pela formatação muito inconsistente do site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlparts = ['http://www2.recife.pe.gov.br/servico/', '?op=NzQ0MQ==']\n",
    "\n",
    "bairros = { \\\n",
    "    'rpa1': ['bairro-do-recife',\n",
    "        'boa-vista',\n",
    "        'cabanga',\n",
    "        'coelhos',\n",
    "        'ilha-do-leite',\n",
    "        'ilha-joana-bezerra',\n",
    "        'paissandu',\n",
    "        'santo-amaro',\n",
    "        'santo-antonio',\n",
    "        'sao-jose',\n",
    "        'soledade'],\n",
    "\n",
    "    'rpa2': ['agua-fria',\n",
    "        'alto-santa-terezinha',\n",
    "        'arruda',\n",
    "        'beberibe',\n",
    "        'bomba-do-hemeterio',\n",
    "        'cajueiro',\n",
    "        'campina-do-barreto',\n",
    "        'campo-grande',\n",
    "        'dois-unidos',\n",
    "        'encruzilhada',\n",
    "        'fundao',\n",
    "        'hipodromo',\n",
    "        'linha-do-tiro',\n",
    "        'peixinhos',\n",
    "        'ponto-de-parada',\n",
    "        'porto-da-madeira',\n",
    "        'rosarinho',\n",
    "        'torreao'],\n",
    "\n",
    "    'rpa3': [#'aflitos',\n",
    "        'alto-do-mandu',\n",
    "        #'alto-jose-bonifacio',\n",
    "        #'alto-jose-do-pinho',\n",
    "        'apipucos',\n",
    "        'brejo-da-guabiraba',\n",
    "        #'brejo-do-beberibe',\n",
    "        'casa-amarela',\n",
    "        'casa-forte',\n",
    "        'corrego-do-jenipapo',\n",
    "        'derby',\n",
    "        #'dois-irmaos',\n",
    "        #'espinheiro',\n",
    "        #'gracas',\n",
    "        'guabiraba',\n",
    "        'jaqueira',\n",
    "        'macaxeira',\n",
    "        'mangabeira',\n",
    "        'monteiro',\n",
    "        'morro-da-conceicao',\n",
    "        'nova-descoberta',\n",
    "        'parnamirim',\n",
    "        #'passarinho',\n",
    "        'pau-ferro',\n",
    "        'poco-da-panela',\n",
    "        'santana',\t\n",
    "        'sitio-dos-pintos',\n",
    "        'tamarineira',\n",
    "        'vasco-da-gama'],\n",
    "\n",
    "    'rpa4': ['caxanga',\n",
    "        'cidade-universitaria',\n",
    "        'cordeiro',\n",
    "        #'engenho-do-meio',\n",
    "        'ilha-do-retiro',\n",
    "        'iputinga',\n",
    "        'madalena',\n",
    "        'prado',\n",
    "        'torre',\n",
    "        'torroes',\n",
    "        'varzea',\n",
    "        'zumbi'],\n",
    "\n",
    "    'rpa5': ['afogados',\n",
    "        'areias',\n",
    "        'barro',\n",
    "        'bongi',\n",
    "        'cacote',\n",
    "        'coqueiral',\n",
    "        #'curado',\n",
    "        'estancia',\n",
    "        'jardim-sao-paulo',\n",
    "        'jiquia',\n",
    "        'mangueira',\n",
    "        'mustardinha',\n",
    "        'san-martin',\n",
    "        'sancho',\n",
    "        'tejipio',\n",
    "        'toto'],\n",
    "\n",
    "    'rpa6': ['boa-viagem',\n",
    "        #'brasilia-teimosa',\n",
    "        'cohab',\n",
    "        'ibura',\n",
    "        'imbiribeira',\n",
    "        'ipsep',\n",
    "        'jordao',\n",
    "        'pina']\n",
    "    }\n",
    "\n",
    "urls = { key : ( bairro.join(urlparts) for bairro in bairros[key] ) for key in bairros }\n",
    "\n",
    "bspages = { key : ( bs(rq.get(url).text, 'html.parser') for url in urls[key] ) for key in urls }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tidos os geradores úteis à coleta de dados, definimos agora as funções que utilizaremos para esse fim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_attrs = { 'class': 'content-text text-servico' }\n",
    "\n",
    "def get_nome_bairro(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    nome_bairro = container.find('h2').text\n",
    "\n",
    "    return nome_bairro\n",
    "\n",
    "def get_dist_marco_zero(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    text = container.find('p').text\n",
    "    dist_texts = re.split('[^0-9.,]+', text)\n",
    "    dist_text = dist_texts[-5] if len(dist_texts) > 8 else dist_texts[-4]\n",
    "    dist_text = re.sub(',', '.', dist_text)\n",
    "    dist = float(dist_text)\n",
    "\n",
    "    return dist\n",
    "\n",
    "def get_area_hectare(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    text = container.find('p').text\n",
    "    area_texts = re.split('[^0-9]+', text)\n",
    "    area_text = area_texts[-4] if len(area_texts) > 11 else area_texts[-3]\n",
    "    area = int(area_text)\n",
    "\n",
    "    return area\n",
    "\n",
    "def get_populacao(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    text = container.find('p').text\n",
    "    pop_texts = re.split('[^0-9.,]+', text)\n",
    "    pop_text = pop_texts[-1] if pop_texts[-1] != '' else pop_texts[-2]\n",
    "    pop_text = re.sub('\\.', '', pop_text)\n",
    "    populacao = int(pop_text)\n",
    "\n",
    "    return populacao\n",
    "\n",
    "def get_pop_masc(bspage):\n",
    "    container = bspage.find('tbody')\n",
    "    pop_masc_text = container.find_all('td')[4].text\n",
    "    pop_masc_text = re.sub('\\.', '', pop_masc_text)\n",
    "    pop_masc = int(pop_masc_text)\n",
    "\n",
    "    return pop_masc\n",
    "\n",
    "def get_pop_fem(bspage):\n",
    "    container = bspage.find('tbody')\n",
    "    pop_fem_text = container.find_all('td')[7].text\n",
    "    pop_fem_text = re.sub('\\.', '', pop_fem_text)\n",
    "    pop_fem = int(pop_fem_text)\n",
    "\n",
    "    return pop_fem\n",
    "\n",
    "def get_pop_faixa_etaria(bspage):\n",
    "    container = bspage.find_all('tbody')[1]\n",
    "    faixas = ['pop_0_4', 'pop_5_14', 'pop_15_17', 'pop_18_24', 'pop_25_59', 'pop_60_']\n",
    "    faixa_tds = container.find_all('td')[4:23:3]\n",
    "    faixa_qtd_txts = [td.text for td in faixa_tds]\n",
    "    faixa_qtd_txts = [re.sub('\\.', '', txt) for txt in faixa_qtd_txts]\n",
    "    faixa_qtds = [int(txt) for txt in faixa_qtd_txts]\n",
    "    pop_faixa = dict(zip(faixas, faixa_qtds))\n",
    "\n",
    "    return pop_faixa\n",
    "\n",
    "def get_pop_porc_raca(bspage):\n",
    "    container = bspage.find_all('tbody')[2]\n",
    "    racas = ['pop_porc_branca', 'pop_porc_preta', 'pop_porc_parda', 'pop_porc_amarela', 'pop_porc_indigena']\n",
    "    racas_tds = container.find_all('td')[3:14:2]\n",
    "    racas_porcs_txts = [td.text for td in racas_tds]\n",
    "    racas_porcs_txts = [re.sub('\\.', '', racas_porc_txt) for racas_porc_txt in racas_porcs_txts]\n",
    "    racas_porcs = [float(re.sub(',', '.', txt)) for txt in racas_porcs_txts]\n",
    "    racas_porcs = dict(zip(racas, racas_porcs))\n",
    "\n",
    "    return racas_porcs\n",
    "\n",
    "def get_alfab_dez_mais(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    alfab_ps = [p.text for p in container.find_all('p')]\n",
    "    alfab_p_text = alfab_ps[1] if alfab_ps[1] != '\\xa0' else alfab_ps[2]\n",
    "    alfab_text = re.split('[^0-9.,]+', alfab_p_text)[3]\n",
    "    alfab_text = re.sub(',', '.', alfab_text)\n",
    "    alfab_dez_mais = float(alfab_text)\n",
    "\n",
    "    return alfab_dez_mais\n",
    "\n",
    "def get_taxa_m_cresc(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ps = container.find_all('p')\n",
    "    p_texts = [p.text for p in ps if p.text != '\\xa0']\n",
    "    p_texts = p_texts[1:]\n",
    "    p_text = ''.join(p_texts)\n",
    "    info_texts = re.split('[^0-9.,-]+', p_text)\n",
    "    info_texts = [text for text in info_texts if text != '.' and text != ',' and text != '-' and text != '']\n",
    "    taxa_text = info_texts[5]\n",
    "    taxa_text = re.sub(',', '.', taxa_text)\n",
    "    taxa_m_cresc = float(taxa_text)\n",
    "\n",
    "    return taxa_m_cresc \n",
    "\n",
    "def get_dens_dem(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ps = container.find_all('p')\n",
    "    p_texts = [p.text for p in ps if p.text != '\\xa0']\n",
    "    p_texts = p_texts[1:]\n",
    "    p_text = ''.join(p_texts)\n",
    "    info_texts = re.split('[^0-9.,]+', p_text)\n",
    "    info_texts = [text for text in info_texts if text != ',' and text != '.' and text != '']\n",
    "    dens_text = info_texts[6]\n",
    "    dens_text = re.sub(',', '.', dens_text)\n",
    "    dens_dem = float(dens_text)\n",
    "\n",
    "    return dens_dem\n",
    "\n",
    "def get_num_domic(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ps = container.find_all('p')\n",
    "    p_texts = [p.text for p in ps if p.text != '\\xa0']\n",
    "    p_texts = p_texts[1:]\n",
    "    p_text = ''.join(p_texts)\n",
    "    info_texts = re.split('[^0-9., ]+', p_text)\n",
    "    info_texts = [text for text in info_texts if text != ',' and text != '.' and text != '' and text != ' ']\n",
    "    num_text = info_texts[8]\n",
    "    num_text = re.sub('\\.', '', num_text)\n",
    "    num_text = re.sub(' ', '', num_text)\n",
    "    num_domic = int(num_text)\n",
    "\n",
    "    return num_domic\n",
    "\n",
    "def get_morador_domic(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ul = container.find('ul')\n",
    "    if ul:\n",
    "        ul = ul.find('li')\n",
    "        md_text = re.match('.+:[^0-9]*([0-9,]+)[^0-9]*', ul.text).group(1)\n",
    "        md_text = re.sub(',', '.', md_text)\n",
    "        morador_domic = float(md_text)\n",
    "    else:\n",
    "        spans = container.find_all('span')\n",
    "        span_texts = [span.text for span in spans if span.text != '\\xa0' and span.text != '']\n",
    "        span_texts = span_texts[-5:]\n",
    "        span_text = ''.join(span_texts)\n",
    "        info_texts = re.split('[^0-9.,]+', span_text)\n",
    "        info_texts = [text for text in info_texts if text != ',' and text != '.' and text != '']\n",
    "        md_text = info_texts[0]\n",
    "        md_text = re.sub(',', '.', md_text)\n",
    "        morador_domic = float(md_text)\n",
    "\n",
    "    return morador_domic\n",
    "\n",
    "def get_prop_resp_fem(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ul = container.find('ul')\n",
    "    if ul:\n",
    "        ul = ul.find_all('li')[1]\n",
    "        resp_text = re.match('.+:[^0-9]*([0-9,]+)[^0-9]*', ul.text).group(1)\n",
    "        resp_text = re.sub(',', '.', resp_text)\n",
    "        prop_resp_fem = float(resp_text)\n",
    "    else:\n",
    "        spans = container.find_all('span')\n",
    "        span_texts = [span.text for span in spans if span.text != '\\xa0' and span.text != '']\n",
    "        span_texts = span_texts[-5:]\n",
    "        span_text = ''.join(span_texts)\n",
    "        info_texts = re.split('[^0-9.,]+', span_text)\n",
    "        info_texts = [text for text in info_texts if text != ',' and text != '.' and text != '']\n",
    "        prop_text = info_texts[1]\n",
    "        prop_text = re.sub(',', '.', prop_text)\n",
    "        prop_resp_fem = float(prop_text)\n",
    "\n",
    "    return prop_resp_fem\n",
    "\n",
    "def get_rend_medio(bspage):\n",
    "    container = bspage.find('div', attrs = first_attrs)\n",
    "    ul = container.find('ul')\n",
    "    if ul:\n",
    "        ul = ul.find_all('li')[2]\n",
    "        rend_text = re.match('.+R\\$\\s*([0-9.,]+)[^0-9]*', ul.text).group(1)\n",
    "        rend_text = re.sub('\\.', '', rend_text)\n",
    "        rend_text = re.sub(',', '.', rend_text)\n",
    "        rend_medio = float(rend_text)\n",
    "    else:\n",
    "        spans = container.find_all('span')\n",
    "        span_texts = [span.text for span in spans if span.text != '\\xa0' and span.text != '']\n",
    "        span_texts = span_texts[-5:]\n",
    "        span_text = ''.join(span_texts)\n",
    "        info_texts = re.split('[^0-9.,]+', span_text)\n",
    "        info_texts = [text for text in info_texts if text != ',' and text != '.' and text != '']\n",
    "        rend_text = info_texts[2]\n",
    "        rend_text = re.sub('\\.', '', rend_text)\n",
    "        rend_text = re.sub(',', '.', rend_text)\n",
    "        rend_medio = float(rend_text)\n",
    "\n",
    "    return rend_medio\n",
    "\n",
    "def get_data_dict(bspage):\n",
    "    data_fields = ['nome_bairro',\n",
    "                    'dist_marco_zero',\n",
    "                    'area_hectare',\n",
    "                    'populacao',\n",
    "                    'pop_masc',\n",
    "                    'pop_fem',\n",
    "                    'alfab_dez_mais',\n",
    "                    'taxa_m_cresc',\n",
    "                    'dens_dem',\n",
    "                    'num_domic',\n",
    "                    'morador_por_domic',\n",
    "                    'prop_resp_fem',\n",
    "                    'rend_medio']\n",
    "\n",
    "    data_funcs = [get_nome_bairro,\n",
    "                    get_dist_marco_zero,\n",
    "                    get_area_hectare,\n",
    "                    get_populacao,\n",
    "                    get_pop_masc,\n",
    "                    get_pop_fem,\n",
    "                    get_alfab_dez_mais,\n",
    "                    get_taxa_m_cresc,\n",
    "                    get_dens_dem,\n",
    "                    get_num_domic,\n",
    "                    get_morador_domic,\n",
    "                    get_prop_resp_fem,\n",
    "                    get_rend_medio]\n",
    "\n",
    "    data = [func(bspage) for func in data_funcs]\n",
    "\n",
    "    pop_faixa_etaria = get_pop_faixa_etaria(bspage)\n",
    "    pop_porc_raca = get_pop_porc_raca(bspage)\n",
    "\n",
    "    data_dict = dict(list(zip(data_fields, data)) + list(pop_faixa_etaria.items()) + list(pop_porc_raca.items()))\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos agora uma lista de dataframes para concatenação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [pd.DataFrame([get_data_dict(bspage) for bspage in bspages[key]]) for key in bairros]\n",
    "\n",
    "for n, df in enumerate(dfs):\n",
    "    df['rpa'] = n + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe com dados que faltam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_out_df = pd.DataFrame({\n",
    "    #Bairros faltando:\n",
    "    #Aflitos\n",
    "    #Alto José Bonifácio\n",
    "    #Alto José do Pinho\n",
    "    #Brejo do Beberibe\n",
    "    #Dois Irmãos\n",
    "    #Espinheiro\n",
    "    #Graças\n",
    "    #Passarinho\n",
    "    #Engenho do Meio\n",
    "    #Curado\n",
    "    #Brasília Teimosa\n",
    "    'nome_bairro': ['Aflitos',\n",
    "                        'Alto José Bonifácio',\n",
    "                        'Alto José do Pinho',\n",
    "                        'Brejo do Beberibe',\n",
    "                        'Dois Irmãos',\n",
    "                        'Espinheiro',\n",
    "                        'Graças',\n",
    "                        'Passarinho',\n",
    "                        'Engenho do Meio',\n",
    "                        'Curado',\n",
    "                        'Brasília Teimosa'],\n",
    "\n",
    "    'dist_marco_zero': [3.72, 7.27, 6.05, 9.34, 10.4, 3.09, 3.71, 10.97, 8, 9.68, 2.33],\n",
    "\n",
    "    'area_hectare': [31, 57, 41, 64, 585, 73, 144, 406, 87, 798, 61],\n",
    "\n",
    "    'populacao': [5773, 12462, 12334, 8292, 2566, 10438, 20538, 20305, 10211, 16418, 18334],\n",
    "\n",
    "    'pop_masc': [2541, 5863, 5617, 3938, 1251, 4465, 8842, 9954, 4609, 7753, 8571],\n",
    "\n",
    "    'pop_fem': [3232, 6599, 6717, 4354, 1315, 5973, 11696, 10371, 5602, 8665, 9773],\n",
    "\n",
    "    'alfab_dez_mais': [99.2, 91, 91.7, 90.2, 93.1, 98.1, 99.2, 87.1, 96.1, 90.3, 91.8],\n",
    "\n",
    "    'taxa_m_cresc': [2.8, .07, -0.08, 3.62, -1.7, 1.6, 1.6, 2.79, -0.34, 1.99, -0.44],\n",
    "\n",
    "    'dens_dem': [187.83, 219.26, 298.4, 129.86, 4.39, 142.56, 143.08, 49.98, 117.54, 20.56, 302.81],\n",
    "\n",
    "    'num_domic': [1937, 3570, 3510, 2459, 737, 3602, 7015, 5792, 3053, 4900, 5464],\n",
    "\n",
    "    'morador_por_domic': [3, 3.5, 3.5, 3.4, 3.5, 2.9, 2.9, 3.5, 3.3, 3.3, 3.4],\n",
    "\n",
    "    'prop_resp_fem': [51.24, 42.64, 53.72, 48.21, 44.1, 49.28, 49.18, 41.31, 46.09, 40.08, 49.57],\n",
    "\n",
    "    'rend_medio': [1028.96, 908.76, 1101.22, 1058.37, 1936.1, 7299.96, 9484.01, 824.02, 2594.45, 1216.36, 1220.81],\n",
    "\n",
    "    'pop_0_4': [240, 911, 785, 655, 177, 469, 794, 1733, 486, 1258, 1285],\n",
    "\n",
    "    'pop_5_14': [546, 2085, 2027, 1514, 427, 892, 1904, 3940, 1204, 2757, 2854],\n",
    "\n",
    "    'pop_15_17': [224, 696, 644, 450, 151, 327, 838, 1242, 464, 830, 907],\n",
    "\n",
    "    'pop_18_24': [695, 1596, 1507, 1094, 372, 1285, 2608, 2731, 1170, 1928, 2156],\n",
    "\n",
    "    'pop_25_59': [3030, 5996, 6022, 3978, 1241, 5415, 10648, 9354, 2242, 8319, 9084],\n",
    "\n",
    "    'pop_60_': [1038, 1188, 1349, 601, 198, 2050, 3746, 1305, 1645, 1326,   2048],\n",
    "\n",
    "    'pop_porc_branca': [76.11, 25.49, 29.02, 31.5, 35.39, 70.56, 76.68, 25.24, 43.49, 33.91, 33.05],\n",
    "\n",
    "    'pop_porc_preta': [1.87, 4.81, 15.65, 9.85, 7.91, 3.43, 2.4, 7.75, 7.56, 8.02, 8.93],\n",
    "\n",
    "    'pop_porc_parda': [21.13, 58.9, 53.57, 57.18, 55.53, 25.03, 19.85, 66.65, 47.25, 56.94, 56.62],\n",
    "\n",
    "    'pop_porc_amarela': [.87, .67, 1.39, 1.45, 1.09, .8, .96, .32, 1.24, .9, .99],\n",
    "\n",
    "    'pop_porc_indigena': [.02, .13, .37, .02, 1.09, .18, .1, .04, .39, .23, .31],\n",
    "\n",
    "    'rpa': [3, 3, 3, 3, 3, 3, 3, 3, 4, 5, 6]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserimos o DataFrame dos bairros ausentes ao fim da lista de DataFrames e concatenamos todos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "dfs.append(left_out_df)\n",
    "\n",
    "final_df = pd.concat(dfs, ignore_index = True)\n",
    "pd.DataFrame.to_csv(final_df, 'dados_preliminares.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, substituímos alguns dados incorretos por seus reais valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dados_preliminares.csv')\n",
    "\n",
    "def fill_missing(df, col_name, bairro, new_val):\n",
    "    df.loc[df['nome_bairro'] == bairro, col_name] = new_val\n",
    "\n",
    "#Correção de áreas em hectares:\n",
    "h_bs = ['Casa Amarela',\n",
    "        'Poço da Panela',\n",
    "        'Santana',\n",
    "        'Sítio dos Pintos',\n",
    "        'Mustardinha',\n",
    "        'Pau-Ferro']\n",
    "\n",
    "h_vs = [188, 81, 47, 180, 63, 44]\n",
    "\n",
    "for i, bairro in enumerate(h_bs):\n",
    "    fill_missing(df, 'area_hectare', bairro, h_vs[i])\n",
    "\n",
    "#Erro no bairro do Jordão:\n",
    "fill_missing(df, 'taxa_m_cresc', 'Jordão', .49)\n",
    "\n",
    "final_df = df\n",
    "\n",
    "pd.DataFrame.to_csv(final_df, 'dados_corrigidos.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
